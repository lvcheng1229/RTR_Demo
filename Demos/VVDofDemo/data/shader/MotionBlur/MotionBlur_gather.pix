#version 120 or 150 compatibility// -*- c++ -*-
#extension GL_EXT_gpu_shader4 : require
/** \file MotionBlur_gather.pix

   This is designed to read from a G3D-style velocity (optical flow) buffer.
   For performance, you could just write out velocity in the desired 
   format rather than adjusting it per texture fetch.
 */
// Included by all of the blur shaders
#include <compatibility.glsl>

#expect maxBlurRadius "int > 0"
#expect numSamplesOdd

// Set to 0 to make very thin objects appear correct, set to 1 to reduce noise but
// undersample single-pixel thick moving objects
#define SMOOTHER 1

uniform float2      SS_POSITION_CHANGE_readScaleBias;

/** Unprocessed differences between previous and current frame in screen space. Guard band. */
uniform sampler2D   SS_POSITION_CHANGE_buffer;

/** Uses the same encoding as SS_POSITION_CHANGE.  No guard band. */
uniform sampler2D   neighborMaxBuffer;

/** No guard band. */
uniform sampler2D   colorBuffer;

/** Typical hyperbolic depth buffer: close values are greater than distant values. Guard band. */
uniform sampler2D   depthBuffer;

/** Amount on [-0.5, 0.5] to randomly perturb samples by at each pixel */
float2              jitter;

/** 32x32 tiled random numbers */
uniform sampler2D   randomBuffer;

/** In fraction of frame duration */
uniform float       exposureTime;

uniform ivec2       trimBandThickness;


/* Measured in pixels
   Make this smaller to better hide tile boundaries
   Make this bigger to get smoother blur (less noise) */
#define varianceThreshold 1.5

#if __VERSION__ < 130
#   define resultColor gl_FragColor.rgb
#else
    out float3 resultColor;
#endif

// Constant indicating locations wme we clamp against the minimum PSF, 1/2 pixel
const float HALF_PIX = 0.5;

/** Computes a pseudo-random number on [0, 1] from pixel position c. */
float hash(int2 c) {
#   if numSamplesOdd <= 5
	    // Use a simple checkerboard if you have very few samples; this gives too much ghosting 
        // for many scenes, however
        return float(int(c.x + c.y) & 1) * 0.5 + 0.25;
#   else
        return texelFetch(randomBuffer, int2(c.x & 31, c.y & 31), 0).r;
#   endif
}


/** Called from readAdjustedVelocity() and readAdjustedNeighborhoodVelocity() */
float2 readAdjustedVelocity(int2 C, sampler2D sampler, out float r) {

	// Raw screen-space movement
    float2 q = texelFetch(sampler, C, 0).xy * SS_POSITION_CHANGE_readScaleBias.x + SS_POSITION_CHANGE_readScaleBias.y;
    float lenq = length(q);

    // Convert the velocity to be a radius instead of a diameter, and scale it by
	// the exposure time
    r = (lenq * 0.5) * exposureTime;
    bool rMuchLargerThanZero = (r >= 0.01);

    // Clamp to the usable distance
    r = clamp(r, HALF_PIX, float(maxBlurRadius));
	
    if (rMuchLargerThanZero) {
        // Adjust q's length based on the newly clamped radius
        return q * (r / lenq);
    } else {
        // We risk having a negligible value in lenq, so just return the original
        // vector, which can't be that long anyway if we entered this case
        return q;
    }
}

/** 
  V[C] in the paper.

  v = half-velocity vector 
  r = magnitude of v
*/
float2 readAdjustedVelocity(int2 C, out float r) {
    return readAdjustedVelocity(C, SS_POSITION_CHANGE_buffer, r);
}

/** NeighborMax[C] from the paper */
float2 readAdjustedNeighborhoodVelocity(int2 C, out float r) {
    return readAdjustedVelocity(int2(C / float(maxBlurRadius)), neighborMaxBuffer, r);
}

float cone(float dist, float r) {
    return saturate(1.0 - abs(dist) / r);
}


float fastCone(float dist, float invR) {
    return saturate(1.0 - abs(dist) * invR);
}

// A cone filter with maximum weight 1 at dist = 0 and min weight 0 at |v|=dist.
float cylinder(float dist, float r) {
    //return 1.0 - smoothstep(r * 0.95, r * 1.05, abs(dist));

    // Alternative: (marginally faster on GeForce, comparable quality)
    return sign(r - abs(dist)) * 0.5 + 0.5;

    // The following gives nearly identical results and may be faster on some hardware,
    // but is slower on GeForce
    //    return (abs(dist) <= r) ? 1.0 : 0.0;
}


/** 0 if depth_A << depth_B, 1 if depth_A >> z_depth, fades between when they are close */
float softDepthCompare(float depth_A, float depth_B) {
    // World space distance over which we are conservative about the classification
    // of "foreground" vs. "background".  Must be > 0.  
    // Increase if slanted surfaces aren't blurring enough.
    // Decrease if the background is bleeding into the foreground.
    // Fairly insensitive
    const float SOFT_DEPTH_EXTENT = 0.02;

    return saturate(1.0 - (depth_B - depth_A) / SOFT_DEPTH_EXTENT);
}

// For linear Z values where more negative = farther away from camera
float softZCompare(float z_A, float z_B) {
    // World space distance over which we are conservative about the classification
    // of "foreground" vs. "background".  Must be > 0.  
    // Increase if slanted surfaces aren't blurring enough.
    // Decrease if the background is bleeding into the foreground.
    // Fairly insensitive
    const float SOFT_Z_EXTENT = 0.1;

    return saturate(1.0 - (z_A - z_B) / SOFT_Z_EXTENT);
}


void main() {
    // Size of the screen
    int2 SCREEN_MAX = textureSize(colorBuffer, 0).xy + trimBandThickness * 2 - int2(1);
    int2 NO_TRIM_BAND_SCREEN_MAX = textureSize(colorBuffer, 0).xy - int2(1);

    // Center pixel
    int2 me       = int2(gl_FragCoord.xy);

    // A pseudo-random number on [-0.5, 0.5]
    float jitter = hash(me) - 0.5;

    resultColor  = texelFetch(colorBuffer, me - trimBandThickness, 0).rgb;

    float depth_center = texelFetch(depthBuffer, me, 0).x;
    
    // Compute the maximum PSF in the neighborhood
    float r_neighborhood;
    float2 v_neighborhood  = readAdjustedNeighborhoodVelocity(me - trimBandThickness, r_neighborhood);

    if (r_neighborhood <= 0.5) {
        // other's no blurring at all in this pixel's neighborhood, since the maximum
        // velocity is less than one pixel.
        return;
    }

    // Compute PSF at me (this pixel)
    float  radius_center;
    float2 velocity_center = readAdjustedVelocity(me, radius_center);

    // Let w be a velocity direction (i.e., w is "omega", a unit vector in screen-space)
    // Let r be a half-velocity magnitude (i.e., a point-spread function radius)

    float2 w_neighborhood = normalize(v_neighborhood);
    // Choose the direction at this pixel to be the same as w_neighborhood if this pixel is not itself moving
    float2 w_center = (radius_center < varianceThreshold) ? w_neighborhood : normalize(velocity_center);

    // Accumulated color; start with the center sample
    // Higher initial weight increases the ability of the background
    // to overcome the out-blurred part of moving objects
    float invRadius_center = 1.0 / radius_center; 
    float totalCoverage = (float(numSamplesOdd) / 40.0) * invRadius_center;
    resultColor *= totalCoverage;

    // Sample along the largest PSF vector in the neighborhood  
    for (int i = 0; i < numSamplesOdd; ++i) {

        // The original algorithm ignores the center sample, but we include it because doing so
        // produces better results for thin objects at the expense of adding a slight amount of grain.
        // That is because the jitter will bounce this slightly off the actual center
#       if SMOOTHER
            if (i == numSamplesOdd / 2) { continue; }
#       endif
        
        // Signed step distance from X to Y.
        // Because cone(r_Y) = 0, we need this to never reach +/- r_neighborhood, even with jitter.
        // If this value is even slightly off then gaps and bands will appear in the blur.
        // This pattern is slightly different than the original paper.
        float t = clamp(lerp(-1.0, 1.0, (float(i) + 1.0 + jitter) / (numSamplesOdd + 1.0)) * 1.2, -1, 1);

        float dist = t * r_neighborhood;

        float2 offset =
            // Alternate between the neighborhood direction and this pixel's direction.
            // This significantly helps avoid tile boundary problems when other are
            // two large velocities in a tile. Favor the neighborhood velocity on the farthest 
			// out taps (which also means that we get slightly more neighborhood taps, as we'd like)
            dist * (((i & 1) == 1) ? w_center : w_neighborhood);  
        
        // Point being considered; offset and round to the nearest pixel center.
        // Then, clamp to the screen bounds
        int2 other = clamp(int2(offset + float2(me) + float2(0.5)), trimBandThickness, SCREEN_MAX);

        float depth_sample = texelFetch(depthBuffer, other, 0).x;

        float radius_sample;

        // The actual velocity_sample vector will be ignored by the code below,
        // but the magnitude (radius_sample) of the blur is used.
        float2 velocity_sample = readAdjustedVelocity(other, radius_sample);
        float3 color_sample    = texelFetch(colorBuffer, clamp(other - trimBandThickness, ivec2(0), NO_TRIM_BAND_SCREEN_MAX), 0).rgb;

        // Relative contribution of sample to the center
        float coverage_sample = 0.0;

        // is other in the foreground or background of me?
        float inFront = softDepthCompare(depth_center, depth_sample);
        float inBack  = softDepthCompare(depth_sample, depth_center);

        // Blurry other over any me
        coverage_sample += inFront * cone(dist, radius_sample);

        // Blurry me, estimate background
        coverage_sample += inBack * fastCone(dist, invRadius_center);

        // Mutually blurry me and other
        coverage_sample += 
			// Optimized implementation
			cylinder(dist, min(radius_center, radius_sample)) * 2.0;
		
			// Code from paper:
			// cylinder(dist, radius_center) * cylinder(dist, radius_sample) * 2.0;

        // Accumulate (with premultiplied coverage)
        totalCoverage += coverage_sample;
        resultColor   += color_sample * coverage_sample;
    }

    // We never divide by zero because we always sample the pixel itself.
    resultColor /= totalCoverage;
}
